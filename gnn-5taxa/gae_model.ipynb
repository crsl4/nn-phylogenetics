{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea66606",
   "metadata": {},
   "source": [
    "# Import Packages and environmental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c6f1490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from os import path\n",
    "sys.path.insert(0, '../')\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfa2b8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26c885d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert string to numbers\n",
    "def convert_string_to_numbers(str, dict):\n",
    "    ''' str: string to convert\n",
    "        dict dictionary with the relative ordering of each char'''\n",
    "            # create a map iterator using a lambda function\n",
    "    # lambda x -> return dict[x]\n",
    "    # This return the value for each key in dict based on str\n",
    "    numbers = map(lambda x: dict[x], str)\n",
    "    # return an array of int64 numbers\n",
    "    return np.fromiter(numbers, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53011b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a graph for each \n",
    "def construct_single_graph(idx, label):\n",
    "    ''' idx: the current graph index w.r.t the label\n",
    "        label: the current label'''\n",
    "    # transform the character of amino acid in to numbers for all 5 sequences in this graph\n",
    "    transformed_x = []\n",
    "    for i in range(5):\n",
    "        # get the index of the sequence from the original dataset\n",
    "        seq_idx = 5*idx + i\n",
    "        transformed_x.append(convert_string_to_numbers(seq_string[seq_idx][:-1], dict_amino))\n",
    "        \n",
    "    # set feature vectors of internal nodes to -1 with same length\n",
    "    vec_len = len(transformed_x[0])\n",
    "    internal_node_vec = np.full(vec_len, -1, dtype=np.int64)\n",
    "    # append the three internal node\n",
    "    for i in range(3):\n",
    "        transformed_x.append(internal_node_vec)\n",
    "    # create the node feature vector\n",
    "    x = torch.tensor(transformed_x, dtype=torch.float)\n",
    "    \n",
    "    # now we create the edge set w.r.t the label\n",
    "    # This part is quite dumb as I'm hard coding the 15 edge set\n",
    "    if label == 0:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[1,5],[5,1],\n",
    "                                   [5,6],[6,5],[4,6],[6,4],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [3,7],[7,3]], dtype=torch.long)\n",
    "    elif label == 1:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[1,5],[5,1],\n",
    "                                   [5,6],[6,5],[3,6],[6,3],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    elif label == 2:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[1,5],[5,1],\n",
    "                                   [5,6],[6,5],[2,6],[6,2],\n",
    "                                   [6,7],[7,6],[3,7],[7,3],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    elif label == 3:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[2,5],[5,2],\n",
    "                                   [5,6],[6,5],[4,6],[6,4],\n",
    "                                   [6,7],[7,6],[3,7],[7,3],\n",
    "                                   [1,7],[7,1]], dtype=torch.long)\n",
    "    elif label == 4:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[2,5],[5,2],\n",
    "                                   [5,6],[6,5],[3,6],[6,3],\n",
    "                                   [6,7],[7,6],[4,7],[7,4],\n",
    "                                   [1,7],[7,1]], dtype=torch.long)\n",
    "    elif label == 5:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[2,5],[5,2],\n",
    "                                   [5,6],[6,5],[1,6],[6,1],\n",
    "                                   [6,7],[7,6],[4,7],[7,4],\n",
    "                                   [3,7],[7,3]], dtype=torch.long)\n",
    "    elif label == 6:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[3,5],[5,3],\n",
    "                                   [5,6],[6,5],[4,6],[6,4],\n",
    "                                   [6,7],[7,6],[1,7],[7,1],\n",
    "                                   [2,7],[7,2]], dtype=torch.long)\n",
    "    elif label == 7:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[3,5],[5,3],\n",
    "                                   [5,6],[6,5],[2,6],[6,2],\n",
    "                                   [6,7],[7,6],[1,7],[7,1],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    elif label == 8:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[3,5],[5,3],\n",
    "                                   [5,6],[6,5],[1,6],[6,1],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    elif label == 9:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[4,5],[5,4],\n",
    "                                   [5,6],[6,5],[3,6],[6,3],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [1,7],[7,1]], dtype=torch.long)\n",
    "    elif label == 10:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[4,5],[5,4],\n",
    "                                   [5,6],[6,5],[2,6],[6,2],\n",
    "                                   [6,7],[7,6],[3,7],[7,3],\n",
    "                                   [1,7],[7,1]], dtype=torch.long)\n",
    "    elif label == 11:\n",
    "        edge_index = torch.tensor([[0,5],[5,0],[4,5],[5,4],\n",
    "                                   [5,6],[6,5],[1,6],[6,1],\n",
    "                                   [6,7],[7,6],[3,7],[7,3],\n",
    "                                   [2,7],[7,2]], dtype=torch.long)\n",
    "    elif label == 12:\n",
    "        edge_index = torch.tensor([[1,5],[5,1],[2,5],[5,2],\n",
    "                                   [5,6],[6,5],[0,6],[6,0],\n",
    "                                   [6,7],[7,6],[3,7],[7,3],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    elif label == 13:\n",
    "        edge_index = torch.tensor([[1,5],[5,1],[3,5],[5,3],\n",
    "                                   [5,6],[6,5],[0,6],[6,0],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [4,7],[7,4]], dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor([[1,5],[5,1],[4,5],[5,4],\n",
    "                                   [5,6],[6,5],[0,6],[6,0],\n",
    "                                   [6,7],[7,6],[2,7],[7,2],\n",
    "                                   [3,7],[7,3]], dtype=torch.long)\n",
    "    \n",
    "    # Now we create the graph object as Data\n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad071d",
   "metadata": {},
   "source": [
    "# File inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f2eb7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training the Garph Auto Encoder for 5-taxa dataset\n",
      "------------------------------------------------------------------------\n",
      "Executing gae_model.py following gae.json\n",
      "------------------------------------------------------------------------\n",
      "Loading Sequence Data in sequences12062021.in\n",
      "Loading Label Data in labels12062021.in\n",
      "Number of samples:10000; Sequence length of each sample:1550\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get name of the script\n",
    "# nameScript = sys.argv[0].split('/')[-1]\n",
    "nameScript = \"gae_model.py\"\n",
    "# get json file name of the script\n",
    "nameJson = \"gae.json\"\n",
    "# nameJson = sys.argv[1]\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Training the Garph Auto Encoder for 5-taxa dataset\")\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Executing \" + nameScript + \" following \" + nameJson, flush = True)\n",
    "\n",
    "# opening Json file \n",
    "jsonFile = open(nameJson) \n",
    "dataJson = json.load(jsonFile)\n",
    "\n",
    "# loading the input data from the json file\n",
    "ngpu = dataJson[\"ngpu\"]                  # number of GPUS\n",
    "lr = dataJson[\"lr\"]                      # learning rate\n",
    "# TODO: batch size\n",
    "# TODO: number of epoch\n",
    "\n",
    "data_root = dataJson[\"dataRoot\"]         # data folder\n",
    "model_root = dataJson[\"modelRoot\"]       # folder to save the data\n",
    "\n",
    "label_files = dataJson[\"labelFile\"]      # file with labels\n",
    "sequence_files = dataJson[\"matFile\"]     # file with sequences\n",
    "\n",
    "if \"summaryFile\" in dataJson:\n",
    "    summary_file = dataJson[\"summaryFile\"]\n",
    "else :\n",
    "    summary_file = \"summary_file.txt\"\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "print(\"Loading Sequence Data in \" + sequence_files, flush = True)\n",
    "print(\"Loading Label Data in \" + label_files, flush = True)\n",
    "\n",
    "# we read the labels as list of strings\n",
    "with open(data_root+label_files, 'r') as f:\n",
    "    label_char = f.readlines()\n",
    "\n",
    "# we read the sequence as a list of strings\n",
    "with open(data_root+sequence_files, 'r') as f:\n",
    "    seq_string = f.readlines()\n",
    "\n",
    "n_samples = len(label_char)\n",
    "seq_length = len(seq_string[0])-1\n",
    "print(\"Number of samples:{}; Sequence length of each sample:{}\"\n",
    "        .format(n_samples, seq_length))\n",
    "print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a06525",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e05e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to extract the dictionary with the relative positions\n",
    "# for each aminoacid\n",
    "\n",
    "# first we need to extract all the different chars\n",
    "strL = \"\"\n",
    "for c in seq_string[0][:-1]:\n",
    "    if not c in strL:\n",
    "        strL += c\n",
    "\n",
    "# we sort them\n",
    "strL = sorted(strL)\n",
    "\n",
    "# we give them a relative order\n",
    "dict_amino = {}\n",
    "for ii, c in enumerate(strL):\n",
    "    dict_amino[c] = ii\n",
    "\n",
    "# looping over the labels and create array. Here each element of the\n",
    "# label_char has the form \"1\\n\", so we only take the first one\n",
    "labels = np.fromiter(map(lambda x: int(x[0])-1,\n",
    "                         label_char), dtype= np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "766ca993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all graphs from raw dataset\n",
    "# empty dataset for all graphs\n",
    "dataset = []\n",
    "for i in range(n_samples):\n",
    "    data = construct_single_graph(i, labels[i])\n",
    "    if (not data.validate(raise_on_error=True)):\n",
    "        print(\"Error! Node number and edge set does not match!\")\n",
    "        break\n",
    "    if (not data.is_undirected()):\n",
    "        print(\"Error! Incorrect edge set!\")\n",
    "        break\n",
    "    dataset.append(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
